{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 615ms/step\n",
      "[[9.9939024e-01 6.0969120e-04 1.7026352e-08 7.0435968e-10]]\n",
      "Image: blue.jpeg - Predicted Class: blue\n",
      "1/1 [==============================] - 0s 400ms/step\n",
      "[[1.3267200e-03 9.9808133e-01 1.8602368e-04 4.0600725e-04]]\n",
      "Image: green.jpeg - Predicted Class: green\n",
      "1/1 [==============================] - 0s 384ms/step\n",
      "[[3.0704381e-08 1.0000000e+00 3.9378891e-09 2.1571708e-10]]\n",
      "Image: green1.jpeg - Predicted Class: green\n",
      "1/1 [==============================] - 0s 389ms/step\n",
      "[[2.5397795e-04 9.9970824e-01 3.7616657e-05 1.2009552e-07]]\n",
      "Image: green2.jpeg - Predicted Class: green\n",
      "1/1 [==============================] - 0s 392ms/step\n",
      "[[8.1593898e-04 9.9814129e-01 8.3260296e-04 2.1008561e-04]]\n",
      "Image: green3.jpeg - Predicted Class: green\n",
      "1/1 [==============================] - 0s 396ms/step\n",
      "[[9.9997008e-01 1.6606572e-09 2.9975419e-05 4.9350998e-08]]\n",
      "Image: orang3.jpeg - Predicted Class: blue\n",
      "1/1 [==============================] - 0s 405ms/step\n",
      "[[3.5172300e-03 5.3284882e-04 9.5638645e-01 3.9563533e-02]]\n",
      "Image: orange.jpeg - Predicted Class: orange\n",
      "1/1 [==============================] - 0s 441ms/step\n",
      "[[9.7636621e-11 1.0032178e-10 1.0000000e+00 1.0349124e-08]]\n",
      "Image: orange2.jpeg - Predicted Class: orange\n",
      "1/1 [==============================] - 1s 679ms/step\n",
      "[[2.68563483e-09 1.10514146e-10 9.99999046e-01 1.00817942e-06]]\n",
      "Image: orange3.jpeg - Predicted Class: orange\n",
      "1/1 [==============================] - 0s 442ms/step\n",
      "[[1.0000000e+00 1.0213003e-14 2.2089089e-13 7.8854756e-13]]\n",
      "Image: orange4.jpeg - Predicted Class: blue\n",
      "1/1 [==============================] - 0s 392ms/step\n",
      "[[8.2403398e-07 2.2696491e-07 9.9999535e-01 3.5857338e-06]]\n",
      "Image: orange5.jpeg - Predicted Class: orange\n",
      "1/1 [==============================] - 0s 402ms/step\n",
      "[[0.9071076  0.00172352 0.03583128 0.05533757]]\n",
      "Image: orange6.jpeg - Predicted Class: blue\n",
      "1/1 [==============================] - 0s 391ms/step\n",
      "[[0.46820292 0.0087114  0.08149197 0.44159374]]\n",
      "Image: white.jpeg - Predicted Class: blue\n",
      "1/1 [==============================] - 0s 397ms/step\n",
      "[[1.1240419e-03 2.8695859e-04 8.7712622e-01 1.2146280e-01]]\n",
      "Image: white2.jpeg - Predicted Class: orange\n",
      "1/1 [==============================] - 0s 429ms/step\n",
      "[[5.2674882e-09 1.7702606e-08 1.0000000e+00 2.5379088e-09]]\n",
      "Image: white3.jpeg - Predicted Class: orange\n",
      "1/1 [==============================] - 0s 477ms/step\n",
      "[[0.46820292 0.0087114  0.08149197 0.44159374]]\n",
      "Image: white4.jpeg - Predicted Class: blue\n",
      "1/1 [==============================] - 0s 408ms/step\n",
      "[[5.5366627e-07 2.7632880e-06 9.9996579e-01 3.0892701e-05]]\n",
      "Image: white5.jpeg - Predicted Class: orange\n",
      "1/1 [==============================] - 0s 411ms/step\n",
      "[[2.9381976e-08 9.0537862e-09 9.9999964e-01 3.6310715e-07]]\n",
      "Image: white6.jpeg - Predicted Class: orange\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "import os\n",
    "\n",
    "# Define the path to your trained model and the directory of images you want to classify\n",
    "model_path = 'VGG16_image_classifier.h5'\n",
    "image_dir = 'Test'\n",
    "\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "model.class_names = ['blue', 'green', 'orange', 'white']  # Define the class names\n",
    "\n",
    "# Define image dimensions (must match the dimensions used during training)\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "\n",
    "\n",
    "def load_and_preprocess_image(img_path):\n",
    "    \"\"\"\n",
    "    Load and preprocess a single image for the model.\n",
    "    \"\"\"\n",
    "    img = image.load_img(img_path, target_size=(img_height, img_width))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "    img_array = preprocess_input(img_array)  # Preprocess for MobileNetV2\n",
    "    return img_array\n",
    "\n",
    "def predict_image(img_path):\n",
    "    \"\"\"\n",
    "    Predict the class of a single image using the trained model.\n",
    "    \"\"\"\n",
    "    img_array = load_and_preprocess_image(img_path)\n",
    "    predictions = model.predict(img_array)\n",
    "    print(predictions)\n",
    "    predicted_index = np.argmax(predictions[0])\n",
    "    predicted_class = model.class_names[predicted_index]\n",
    "    return predicted_class\n",
    "\n",
    "def classify_images(image_dir):\n",
    "    \"\"\"\n",
    "    Classify all images in the given directory.\n",
    "    \"\"\"\n",
    "    # List all image files in the directory\n",
    "    image_files = [f for f in os.listdir(image_dir) if os.path.isfile(os.path.join(image_dir, f))]\n",
    "    \n",
    "    for img_file in image_files:\n",
    "        img_path = os.path.join(image_dir, img_file)\n",
    "        predicted_class = predict_image(img_path)\n",
    "        print(f\"Image: {img_file} - Predicted Class: {predicted_class}\")\n",
    "\n",
    "# Run the classification\n",
    "classify_images(image_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
