{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 571ms/step\n",
      "[[9.9976569e-01 3.8664766e-06 1.9499095e-04 3.5505040e-05]]\n",
      "Image: blue.jpeg - Predicted Class: blue\n",
      "1/1 [==============================] - 0s 233ms/step\n",
      "[[0.2896742  0.22858128 0.27887607 0.20286848]]\n",
      "Image: green.jpeg - Predicted Class: blue\n",
      "1/1 [==============================] - 0s 210ms/step\n",
      "[[0.01425731 0.7074315  0.2730579  0.00525335]]\n",
      "Image: green1.jpeg - Predicted Class: green\n",
      "1/1 [==============================] - 0s 213ms/step\n",
      "[[2.2274494e-01 7.7691805e-01 3.2882960e-04 8.1388898e-06]]\n",
      "Image: green2.jpeg - Predicted Class: green\n",
      "1/1 [==============================] - 0s 231ms/step\n",
      "[[4.3946557e-08 9.9997032e-01 2.9653480e-05 9.9091313e-10]]\n",
      "Image: green3.jpeg - Predicted Class: green\n",
      "1/1 [==============================] - 0s 231ms/step\n",
      "[[1.000000e+00 7.161232e-21 2.151472e-21 6.513374e-26]]\n",
      "Image: orang3.jpeg - Predicted Class: blue\n",
      "1/1 [==============================] - 0s 231ms/step\n",
      "[[7.0793368e-04 3.6004241e-10 9.9929202e-01 6.2824737e-12]]\n",
      "Image: orange.jpeg - Predicted Class: orange\n",
      "1/1 [==============================] - 0s 228ms/step\n",
      "[[1.4133656e-01 4.8342958e-04 8.4062976e-01 1.7550295e-02]]\n",
      "Image: orange2.jpeg - Predicted Class: orange\n",
      "1/1 [==============================] - 0s 390ms/step\n",
      "[[1.4228547e-04 3.0029059e-07 9.9985731e-01 4.1557623e-08]]\n",
      "Image: orange3.jpeg - Predicted Class: orange\n",
      "1/1 [==============================] - 0s 226ms/step\n",
      "[[1.0000000e+00 2.1581056e-28 0.0000000e+00 8.6573603e-21]]\n",
      "Image: orange4.jpeg - Predicted Class: blue\n",
      "1/1 [==============================] - 0s 241ms/step\n",
      "[[2.8167897e-05 2.8797716e-08 9.9997008e-01 1.8035679e-06]]\n",
      "Image: orange5.jpeg - Predicted Class: orange\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "[[9.9990845e-01 8.9603855e-05 1.8615247e-06 6.1115500e-08]]\n",
      "Image: orange6.jpeg - Predicted Class: blue\n",
      "1/1 [==============================] - 0s 212ms/step\n",
      "[[0.94827044 0.01387847 0.00166726 0.03618379]]\n",
      "Image: white.jpeg - Predicted Class: blue\n",
      "1/1 [==============================] - 0s 238ms/step\n",
      "[[0.10358815 0.00136949 0.5564547  0.33858764]]\n",
      "Image: white2.jpeg - Predicted Class: orange\n",
      "1/1 [==============================] - 0s 241ms/step\n",
      "[[1.3580012e-08 9.8223485e-10 9.9999917e-01 8.9257588e-07]]\n",
      "Image: white3.jpeg - Predicted Class: orange\n",
      "1/1 [==============================] - 0s 224ms/step\n",
      "[[0.94827044 0.01387847 0.00166726 0.03618379]]\n",
      "Image: white4.jpeg - Predicted Class: blue\n",
      "1/1 [==============================] - 0s 301ms/step\n",
      "[[9.9673414e-01 4.8753092e-04 2.7427813e-03 3.5464382e-05]]\n",
      "Image: white5.jpeg - Predicted Class: blue\n",
      "1/1 [==============================] - 0s 227ms/step\n",
      "[[0.00067835 0.00120431 0.38893747 0.60917985]]\n",
      "Image: white6.jpeg - Predicted Class: white\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "import os\n",
    "\n",
    "# Define the path to your trained model and the directory of images you want to classify\n",
    "model_path = 'VGG16_image_classifier.h5'\n",
    "image_dir = 'Test'\n",
    "\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "model.class_names = ['blue', 'green', 'orange', 'white']  # Define the class names\n",
    "\n",
    "# Define image dimensions (must match the dimensions used during training)\n",
    "img_height = 128\n",
    "img_width = 128\n",
    "\n",
    "\n",
    "def load_and_preprocess_image(img_path):\n",
    "    \"\"\"\n",
    "    Load and preprocess a single image for the model.\n",
    "    \"\"\"\n",
    "    img = image.load_img(img_path, target_size=(img_height, img_width))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "    img_array = preprocess_input(img_array)  # Preprocess for MobileNetV2\n",
    "    return img_array\n",
    "\n",
    "def predict_image(img_path):\n",
    "    \"\"\"\n",
    "    Predict the class of a single image using the trained model.\n",
    "    \"\"\"\n",
    "    img_array = load_and_preprocess_image(img_path)\n",
    "    predictions = model.predict(img_array)\n",
    "    print(predictions)\n",
    "    predicted_index = np.argmax(predictions[0])\n",
    "    predicted_class = model.class_names[predicted_index]\n",
    "    return predicted_class\n",
    "\n",
    "def classify_images(image_dir):\n",
    "    \"\"\"\n",
    "    Classify all images in the given directory.\n",
    "    \"\"\"\n",
    "    # List all image files in the directory\n",
    "    image_files = [f for f in os.listdir(image_dir) if os.path.isfile(os.path.join(image_dir, f))]\n",
    "    \n",
    "    for img_file in image_files:\n",
    "        img_path = os.path.join(image_dir, img_file)\n",
    "        predicted_class = predict_image(img_path)\n",
    "        print(f\"Image: {img_file} - Predicted Class: {predicted_class}\")\n",
    "\n",
    "# Run the classification\n",
    "classify_images(image_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
